# Python Diagnose
## Introduction
Run a Python script, print its output, and (optionally) diagnose failures with
an LLM.
This CLI launches a target Python program, captures `stdout`/`stderr`, applies a
few fast local heuristics to suggest likely fixes, and asks an LLM
 to analyze the error and propose minimal changes.
---
## Requirements
- Python 3.9+
- Optional (for LLM diagnosis):
- `langchain-openai`, `dotenv`
- An OpenAIâ€‘compatible API key available to LangChain (e.g., `OPENAI_API_KEY`)
---
## Installation
```bash
# From your project root
pip install -r requirements.txt
# or install the minimal set directly
pip install dotenv langchain-openai
```
---
## Configuration
Create a `.env` (optional) alongside `diagnose.py` or in your working directory:
```
OPENAI_API_KEY=...
```

You can also rely on the environment variable `OPENAI_API_KEY` exported in your shell.
---

## Usage

```bash
python diagnose.py path/to/script.py script_arg1 script_arg2 ...
```

### CLI options
```text
usage: diagnose.py [-h] [--timeout TIMEOUT] [--llm] [--model MODEL] [--trim TRIM] script [script_args ...]

Run a Python script and diagnose errors

positional arguments:
  script                Path to Python script
  script_args           Remaining args passed through to the script

options:
  -h, --help         show this help message and exit
  --timeout TIMEOUT  Time in seconds to analyze before timing out
  --llm, --no-llm    Use LLM (default: True)
  --model MODEL      LLM model name
  --trim TRIM        Max characters to send to LLM
```
